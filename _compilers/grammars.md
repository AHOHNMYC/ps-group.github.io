---
title: "Грамматики"
---

Грамматика указывает на иерархию между символами в формальном языке. Все тексты, соответствующие правилам языка, соответствуют и его грамматике. Иными словами, грамматика &mdash; это набор правил, позволяющих:

- Из грамматического символа верхнего уровня получить любой текст на языке путём рекурсивного раскрытия абстрактных символов в нечто конкретное
- Для любого текста проверить, соответствует ли он грамматике языка, то есть можно ли весь текст назвать символом верхнего уровня на этом языке

В большинстве языков символом верхнего уровня является один файл исходного кода, называемый "модулем" или "единицей трансляции". Например, в языке Python мы можем развернуть абстрактный символ "модуль Python" в список из двух абстрактных (нетерминальных) символов:

```python
<функция>
<ветвление>
```

После мы можем развернуть оба этих символа, и продолжать разворачивать порождённые символы до тех пор, пока *нетерминальные* символы не закончатся, после чего останутся лишь *терминальные* символы:

```python
def main():
    print "Hello, World!"

if __name__ == "__main__":
    main()
```

- Нетерминальные символы абстрактны, и могут быть развёрнуты далее по правилам грамматики языка. Примеры таких символов: "ветвление", "функция", "присваивание", "модуль программы".
- Терминальные символы конкретны, и не могут быть развёрнуты по правилам языка.
- Правило грамматики задаёт преобразование цепочки символов в новую цепочку символов. В том числе это может быть замена одного символа на пять новых, замена трёх символов на ноль символов и так далее.

> Когда надо остановиться и перестать раскрывать символы? Зависит от уровня абстракции грамматики. Вы можете раскрывать вплоть до отдельных символов. Можно остановиться на *токенах* (идентификаторах, числах, знаках операций) и дальше не раскрывать, если у вас есть лексический анализатор, который умеет превращать поток текста в поток более абстрактных токенов.

В промышленных компиляторах парсер (синтаксический анализатор) занимается обратной задачей &mdash; сворачивает токены, полученных лексером (лексическим анализатором), согласно правилам грамматики, и получает абстрактные (нетерминальные) символы "функция", "ветвление", "определение класса" и так далее. Набор символов языка и правил грамматики зависит от языка.

## Иерархия Хомского

Иерархия Хомского &mdash; это общепринятое деление формальных языков на 4 уровня. Чем выше номер типа, тем более скудный язык и тем легче его разбирать программно:

- Тип 0: неограниченные
    - правила замены символов ничем не ограничены, что делает машинный анализ таких текстов невозможным
- Тип 1: контекстно-зависимые
    - правила замены символов зависят от контекста
    - в этом примере на C++ без контекста неясно, что это &mdash; сравнение двух переменных или специализация шаблона: `vec < a > b`.
    - в этом примере неясно, объявлена ли функция "getSize": `getSize(sprite)`
- Тип 2: контекстно-свободные
    - правила описывают замену одного нетерминала на цепочку нетерминалов и терминалов (возможно, пустую), т.е. способ замены каждого нетерминала на другие символы не зависит от контекста
    - формально: в левой части правила может быть только нетерминал, `A → β`, где "A" &mdash; нетерминал, "β" &mdash; цепочка нетерминалов и терминалов
    - например, в языках программирования символ "присваивание" раскрывается однозначно независимо от того, что окружает присваивание
- Тип 3: регулярные
    - праворегулярные грамматики могут содержать три вида правил: `B → α`, `B → αC`, `B → ε`, где "ε" &mdash; пустое множество, "B" и "С" &mdash; нетерминалы, и "α" &mdash; терминал
    - леворегулярные грамматики могут содержать три вида правил: `A → α`, `A → Bα`, `A → ε`, где "ε" &mdash; пустое множество, "A" и "B" &mdash; нетерминалы, и "α" &mdash; терминальный символ

Все реальные языки программирования являются контекстно-зависимыми (тип 1), но большинство может быть разобрано как контекстно-свободные (тип 2) с последующей постобработкой в виде проверок типов и т.п. Не случайно фронтенд компилятора делят на три стадии:

- лексический анализ (в рамках регулярной грамматики текст делится на строковые литералы, числа, идентификаторы, операторы, разделители, убираются пробелы и комментарии)
- синтаксический анализ (в рамках контекстно-свободной грамматики)
- семантический анализ (проверка соответствия контекстно-зависимым правилам, таким как "переменная должна быть объявлена заранее")

## Регулярные грамматики

Любая регулярная грамматика имеет эквивалентное регулярное выражение, а также эквивалентный детерминированный конечный автомат. Это всё три формы одной и той же сущности.

В промышленных библиотеках регулярных выражениях многие операции избыточны с служат лишь для удобства. Если убрать всё лишнее и оставить самый минимум, достаточный для создания произвольных регулярных выражений, то останутся три операции:

- Символ * задаёт итерацию (a.k.a. замыкание Клини)
    - Пример: “1*” ищет строки “”, “1”, “11”, …
- Пустая строка задаёт конкатенацию двух выражений
    - Пример: “ab” ищет подстроку “ab”, “ab*” ищет подстроки вида “a”, “ab”, “abb”, …
- Символ | задаёт объединение
    - Пример: “a|b|c|d” ищут подстроки "a", "b", "c", "d"

На таком языке можно описать выражения для разбора любого регулярного языка.

## Контекстно-свободные грамматики

## Контекстно-зависимые грамматики

## Ссылки

- [Формальная грамматика (ru.wikipedia.org)](https://ru.wikipedia.org/wiki/%D0%A4%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)
- [Иерархия Хомского (ru.wikipedia.org)](https://ru.wikipedia.org/wiki/%D0%98%D0%B5%D1%80%D0%B0%D1%80%D1%85%D0%B8%D1%8F_%D0%A5%D0%BE%D0%BC%D1%81%D0%BA%D0%BE%D0%B3%D0%BE)
